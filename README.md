# ml_interpretability

Examples of Machine Learning interpretability libraries.

You will find:
- Feature Importance
- LIME
- SHAP

Some of the notebooks are based on notebooks from the SHAP github.
